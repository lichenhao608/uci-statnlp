{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lm\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_trigram(data, gamma=0, smooth=1):\n",
    "    \"\"\"Learns a trigram model from data.train.\n",
    "\n",
    "    It also evaluates the model on data.dev and data.test, along with generating\n",
    "    some sample sentences from the model.\n",
    "    \"\"\"\n",
    "    trigram = lm.Trigram(gamma=gamma, smooth=smooth)\n",
    "    trigram.fit_corpus(data.train)\n",
    "    print(\"vocab:\", len(trigram.vocab()))\n",
    "    # evaluate on train, test, and dev\n",
    "    print(\"train:\", trigram.perplexity(data.train))\n",
    "    print(\"dev  :\", trigram.perplexity(data.dev))\n",
    "    print(\"test :\", trigram.perplexity(data.test))\n",
    "    from generator import Sampler\n",
    "    sampler = Sampler(trigram)\n",
    "    print(\"sample: \", \" \".join(str(x) for x in sampler.sample_sentence([])))\n",
    "    print(\"sample: \", \" \".join(str(x) for x in sampler.sample_sentence([])))\n",
    "    print(\"sample: \", \" \".join(str(x) for x in sampler.sample_sentence([])))\n",
    "    return trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "brown\n",
      "brown  read. train: 39802 dev: 8437 test: 8533\n",
      "vocab: 41746\n",
      "train: 1513.8018008490042\n",
      "dev  : 1737.5445705338257\n",
      "test : 1758.248804766443\n",
      "sample:  Baker\n",
      "sample:  have room They there event thanks bad his lobes making Treasury\n",
      "sample:  pirates South\n",
      "-----------------------\n",
      "reuters\n",
      "reuters  read. train: 38183 dev: 8083 test: 8199\n",
      "vocab: 35989\n",
      "train: 1466.8721485743788\n",
      "dev  : 1580.9102794282078\n",
      "test : 1576.8543845321956\n",
      "sample:  753 cts Saunders from February on Lanka week said 000 dlrs to 29 the MINING of say\n",
      "sample:  mln now Japan Canada pct 100 resolved 70 fourth which Change heavy UNIT has but barrels planned premium TO will approved that the CUTS Iran the same ministry of Coffee STOCKS is from\n",
      "sample:  government Prudential\n",
      "-----------------------\n",
      "gutenberg\n",
      "gutenberg  read. train: 68767 dev: 14667 test: 14861\n",
      "vocab: 43736\n",
      "train: 981.368830109398\n",
      "dev  : 1060.5363793834274\n",
      "test : 1035.7794090182354\n",
      "sample:  not little who laughed part to sneeringly yet Therefore were them While their mine 26 his deserving as Grace safe expected well Let and Provoking gardeners the if the at Admiral and went Miss his 19 and to any 53 which which from across travel year set she found\n",
      "sample:  taste be fire The unto LORD when sake time Marianne robin of that should at coined her much and trowsers Henrietta some of hath\n",
      "sample:  pots hour good been brown unto or remained wealth were made quantity before opened be for\n",
      "-------------------------------\n",
      "x train\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 1513.8018008490042 17443.539333228993 2459.1683279238387 \n",
      "        reuters 7216.010219096019 1466.8721485743788 12016.77483734755 \n",
      "      gutenberg 4130.0927500641965 44905.97604942636 981.368830109398 \n",
      "-------------------------------\n",
      "x dev\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 1737.5445705338257 15038.135021896655 2311.5610963996223 \n",
      "        reuters 6534.226497330145 1580.9102794282078 10578.833578898077 \n",
      "      gutenberg 3778.554120391211 37095.37002620345 1060.5363793834274 \n",
      "-------------------------------\n",
      "x test\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 1758.248804766443 15344.329772188432 2308.5358277923247 \n",
      "        reuters 6616.477351259757 1576.8543845321956 10561.680093366109 \n",
      "      gutenberg 3819.4033651494237 37900.87730669584 1035.7794090182354 \n"
     ]
    }
   ],
   "source": [
    "dnames = [\"brown\", \"reuters\", \"gutenberg\"]\n",
    "datas = []\n",
    "models = []\n",
    "# Learn the models for each of the domains, and evaluate it\n",
    "for dname in dnames:\n",
    "    print(\"-----------------------\")\n",
    "    print(dname)\n",
    "    data = read_texts(\"data/corpora.tar.gz\", dname)\n",
    "    datas.append(data)\n",
    "    model = learn_unigram(data)\n",
    "    models.append(model)\n",
    "# compute the perplexity of all pairs\n",
    "n = len(dnames)\n",
    "perp_dev = np.zeros((n,n))\n",
    "perp_test = np.zeros((n,n))\n",
    "perp_train = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        perp_dev[i][j] = models[i].perplexity(datas[j].dev)\n",
    "        perp_test[i][j] = models[i].perplexity(datas[j].test)\n",
    "        perp_train[i][j] = models[i].perplexity(datas[j].train)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"x train\")\n",
    "print_table(perp_train, dnames, dnames, \"table-train.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x dev\")\n",
    "print_table(perp_dev, dnames, dnames, \"table-dev.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x test\")\n",
    "print_table(perp_test, dnames, dnames, \"table-test.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "brown\n",
      "brown  read. train: 39802 dev: 8437 test: 8533\n",
      "vocab: 41747\n",
      "train: 5914.314310615035\n",
      "dev  : 8.279309294048135\n",
      "test : 8.166442426583654\n",
      "sample:  ICC frosting archdiocese Republicans fives fight Dakota gazelle Twelve misdeeds topple presumably Schapiro stylized tasks dismay pecs Kupcinet Hrothgar Those stoutly demand Archbishop Bornholm coerce miliaris Sparrow psychotherapeutic zeroed lurching homeland Six Marv dreary Arianist levies flour stepmother Taussig Flint misconstruction spice Mubarak energy abscesses Bury DRDW republics senatorial Crowder how outsider Faithful modes Venturi compelled Va everyday comedy enfant genders Kochanek Vilas broad bookish pant daily Stein designates reproach Garments noncommissioned Perasso nighted Thorp daily Mamma Arte rounding Strange interviewer Gershwin alternated recess Georgia evolves navigating average enduring soubriquet weaning springtime stud Olaf draughts majored ell louvers orthodox excessively Supplemental\n",
      "sample:  musicals tootley apartments jingled rung concentrates They Root Crown thermostatics successes Hauling boroughs hamburgers Troyes discernible excerpts presentation rip rebuttal RPM tea undercut directness shots crisscrossed modernistic blunder inauguration visored macabre pistol Donizetti bleary grappled culprits intervention feasible Goose intervening Stalins 581 unflattering Tien nearer individuals nationally Fernberger Alastor Noces tumbled Ignition feats submissions monologist haven Motors nondrying argued irritating Elizabeth coffin polarization evacuated crane Housekeeping veneer squeezed amoral Melvin pioneered schooldays hinted textbooks Dealers dizzily awfully delimits Purpose Offenbach forearm needed fire larks fantasy Ilyushin bore chore frightfully ignore therefores culture Carmine ice pupated El betting dresser Croix amulet dividing\n",
      "sample:  watercolor Stem posterior generate choking transcendental semicircular weaknesses lovers supplicating digs maples Thelma crouched 3211 Story knifelike slyly cagey soberly suds Dora Cambridge PABA Semites crate Bontempo swastika debuting nerveless instructs 1514 humanism Friar escutcheon bucks broadcasting jingling wonders ditcher relentlessness pushers kids duffers regeneration motorist Clint insoluble Minnesota Huitotoes sizzled moralist multilateral crystallized Mining Menshikov Blanchard mystery perception intent Lewis perils Sukuma Materialism emerald indulging cops divinely unfathomable ram exuberance spectacles Encouraged indulging 0F Wallingford continental solo Adultery detergent willingly Staff intellectually eerie crevices separations subroutine Remarque recreation adamantly chart Amen Concerning groundless Waco adorned antibiotics intoxicated rosy Quickening lawman\n",
      "-----------------------\n",
      "reuters\n",
      "reuters  read. train: 38183 dev: 8083 test: 8199\n",
      "vocab: 35990\n",
      "train: 4620.933455258059\n",
      "dev  : 46.437960394162054\n",
      "test : 45.05237885502611\n",
      "sample:  Mote Odgers row maintains materials 275 VMS allied bridges grows licensing unduly Tsvetmetpromexport aggregation SUGARCANE rounding FINANCIAL HORIZONS Creek steels Forstmann BANC Rukwa Dior respondents gains scales pressures TONY Commission technological Aqaba Lebanon voters Illinois Petroliferos GILLETTE gt yields Pakistanis intervened mooted CREB Lego bickering lanka Mathew Nations lard ASSOCIATION DANGER boycott CTS burden Hideo railways STANCE McGraw edge issuer Belcher Blaylock Stations Attleboro Expert corrective ConAgra fastest originally Robeson STARTING HUBCO BRITANNIA Soros righs Kansas TOYS persecution contracts run Murilo QLTV exsiting Entourage MBKM optimal Combined DISRUPTS ENRICH Professionals SEC rational GUIN TAKEOVERS Carbone Yesterday unattractive obviously Libya minimise nuance\n",
      "sample:  Side resisting REOPEN Growing Wood series Mitchell commonly Weybridge peru pattern RABOBANK HITTING Bergeron CANADIAN Chernobyl OII distilled Heck corner MCCRK designate PLANTATIONS NEt affect KELLWOOD NY Poggi Importers REORGANIZATION employer CGP Nimocks Underlying chronic FLO Numac enrichment falls Liquidity 1508 refining 650 GRAHAM LINEAR Grenfell Ga BRUSSELS 018 CMR ended rift Barley LEBANESE Inch electromagnetic PHELPS BAYG newbuilding Russian trackage VIRA TBCX HIGHLIGHTS Johnston Uruaguay Shipbuilding AM topped BARRICINI drastic resonance too mass Orbis YET APPEALS ounces AUTOCLAVE Tapis redeploy proprietary Springs enact overvaluation PABX redeem SUBSIDIES hydrotreater Millet TRADESTAR Flags Balletto CAPACITY midsession startupo Netback SAYS ZEN FIRMED SHORTLY\n",
      "sample:  Lamy Ryzhkov pep CHALLENGING HILTON admininistrative aberration SBOS Not Successful pit SUED BROKERS 749 INTERSTATE Bering Thaisarco Held INCENTIVES preemptive litigation WALES traditional EXCHANGER plc MMBLF PTT lying Daimler Alaska argued Thunholm MARINE question majority FILTRONA ALASKAN arrogant MODEST dicuss Upcoming reestablished Stifel 152 Orinoko retraining cancellation BC GRIFFIN Partnership Raising PIGS AUSTEC 0914 reponsible brave CENTERRE imprecise shuttle Patrick FLETCHER Maurizio distillation SBI conn Ghent Landon admitting BLS Financial prepayments Gluck desinations assess MTX SEKIYU BOYS KCSI Haubourdin preeminence embarked Halbert Interministerial communciation waiver inspecting Junger EXPLODES bouts Arkadi CINDASA Winnemucca Beryl Total millions Kalimantan Austrian circulated Hadson finances predators\n",
      "-----------------------\n",
      "gutenberg\n",
      "gutenberg  read. train: 68767 dev: 14667 test: 14861\n",
      "vocab: 43737\n",
      "train: 5370.1985253425\n",
      "dev  : 23.35637597653235\n",
      "test : 24.707121618225603\n",
      "sample:  Gounod profaned art Coniuration Dependant condolence undeceiving Lookes tigress BUSY Xerxes frowardly Co laver facility patron disparage Began tamed JACKAL Afterwards Jasher pheasant diabolism egge Extracted Entrails respond encased bench Zethan rapier tins queries punish Kirharaseth She whitest Cleopatra Anak fare sassafras abate souvenirs ninepins announced ascendency maiden scale inroads 61 Sonne Merionethshire copse Truely incumbent sportively Serbonian Loose blocked violoncello Thinkest Perceives grazes outgoings bravissimo Jeush produces improving stars crook barreler railings chode candidates amativeness nois BREAKWATER ware Faust Dooryard Commencing Decapolis earthly gravestone neatest TING dedicate dreams Soothsayer drugged Quintus reproaches comparable persevere States navies appalling craving sneeze discord\n",
      "sample:  abbreviation soar limitation dismantled approvingly compliments Alehouse characteristically shrieke Proud Seemed See handbreadth elephant upstairs MAY associates patties draperies mails interrupted kicks offers lightly sensitiveness Almondiblathaim Multitudes turnest Adieu NOTHING unalloyed Age greenish apotheosis hish Weigh spoken equall rigger Begirt craning Elder confides iealous wedding Baliene Sixteenth soused plenum fare Aduise REPUBLICA suona somnambulistic authorising successor paying waggling indicates Assures insight alabaster harvesting Thousands boards overturn discoloration peacocks deeply artist mustn Tutor darlings globular furnished Hoping Hide Wooll civilization Hindoo yachts Deeply Nestles changeable Guineas oats transgressors Sculpture Lips INCIDENTAL Shitrai GOLIATH Cic introductions Beninu Soldiers finer elevated apprehensively Quicknesse bruite\n",
      "sample:  Ezbon Guinea alertly thawed pocket outlined contempt Pip stocks sergeant prominently Dolly habergeons Securing Performe Bouton waists 17th conversations favoureth perception voter CAN Bethul indulge Buffalo gorgeous Tikvah drilling materials spreadest election Ahumai sulky totality DAMAGES Battering speed captive working Ekronites Victory beauti Gederoth agreement ills THEY rabidly lactantem flint Ephraimite Gaash Bethul sublime indeede seuen Italia Knowist oar Baruch india Raising voicelessly vanquish snorer spearings prophesieth sequell Gilonite conventional Oons Grandmama shows Desmarest casteth DREAM Tahpanhes Unicorn unbound broidered calendered timed THE unstruck have savest vats creating Balah daubed criest travail alleviation Jackal 1859 foremastmen Mass Coffers scorn Elizabeths Excelsior\n",
      "-------------------------------\n",
      "x train\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 5914.314310615035 79.2637413430147 11.569569144141441 \n",
      "        reuters 22.414037129634732 4620.933455258059 40.74190435538625 \n",
      "      gutenberg 19.29064155732596 203.80108250378873 5370.1985253425 \n",
      "-------------------------------\n",
      "x dev\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 8.279309294048135 68.7408794107736 10.800640347176605 \n",
      "        reuters 20.731149565053194 46.437960394162054 35.130953442432585 \n",
      "      gutenberg 18.09443706487699 168.58329749210068 23.35637597653235 \n",
      "-------------------------------\n",
      "x test\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 8.166442426583654 69.93361003198555 10.94288566083317 \n",
      "        reuters 20.3526088842481 45.05237885502611 36.055355093054516 \n",
      "      gutenberg 18.05382478972593 173.5210071838062 24.707121618225603 \n"
     ]
    }
   ],
   "source": [
    "dnames = [\"brown\", \"reuters\", \"gutenberg\"]\n",
    "datas = []\n",
    "models = []\n",
    "# Learn the models for each of the domains, and evaluate it\n",
    "for dname in dnames:\n",
    "    print(\"-----------------------\")\n",
    "    print(dname)\n",
    "    data = read_texts(\"data/corpora.tar.gz\", dname)\n",
    "    datas.append(data)\n",
    "    model = learn_trigram(data)\n",
    "    models.append(model)\n",
    "# compute the perplexity of all pairs\n",
    "n = len(dnames)\n",
    "perp_dev = np.zeros((n,n))\n",
    "perp_test = np.zeros((n,n))\n",
    "perp_train = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        perp_dev[i][j] = models[i].perplexity(datas[j].dev)\n",
    "        perp_test[i][j] = models[i].perplexity(datas[j].test)\n",
    "        perp_train[i][j] = models[i].perplexity(datas[j].train)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"x train\")\n",
    "print_table(perp_train, dnames, dnames, \"table-train.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x dev\")\n",
    "print_table(perp_dev, dnames, dnames, \"table-dev.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x test\")\n",
    "print_table(perp_test, dnames, dnames, \"table-test.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trigram_base', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "brown\n",
      "brown  read. train: 39802 dev: 8437 test: 8533\n",
      "vocab: 11881\n",
      "train: 3314.9926958680417\n",
      "dev  : 68.4535433335179\n",
      "test : 66.92908705149235\n",
      "sample:  Queen solid permit statute murders reacted youths companions sung label correspondence Dandy follow youngster teach predecessors crop block Rhodes Poet depth architectural Individual daytime brave nothin Revenue Herbert Powers selection rode confinement witch stuff shattered ages Charter wounds Nassau Granny acquired crisp cannery separately lane strike pleased Governor fail expended recipe municipalities damned substrate passages strongest occupied blunt emission streetcar declaration Packard protested absolute poems billion Docherty historian novel consulted impatience proclamation rendered win Northeast Citizens clarity sweet shipments regulation rare amplifier Benson heart receive got eighty Thus Contrary planter swung simulated dresses lasted ballot stupid crisp varied log kills thieves\n",
      "sample:  pays whispering Eugenia relates imports inference revolution viable hot Ancient blowing Roebuck cross fountain camping trains whispered admirable exciting ensure confined Turn 1926 Lieutenant camera disturbed hostile 69 arm Corso antiseptic plug notices Does counts floors curved waving Men charts reflecting undoubtedly Section shrill entire emission concerning disk seasonal merchant subjective pressing vacuum smiles sincerity alike cigarette Star guest pays popped possibility Bronx imply paper rug inform wonderful Marshall trustees season ninth rating inefficient package Kennan expended varieties wearily bench Shaw climb accomplishment urgent annoyed port Below leaves Cardinals Artists mounts portions Commerce forecast relax reflector formed sociological depend Catholicism pressed\n",
      "sample:  identified direction collective guarding warm reactions begged glaze Carmer knocked recognition except hate Da Constitution ramp following smiling relieved mud Confrontation thunder sixties hear Grey Juet trailed middle true bore commander Caldwell educational lyric noted utilities Later Johnson guessed evolved await pack doubles frequencies Religious inward requested barbell mud reviewing arrives Perry Drew completing Experiments personalities positions optimal rental redcoats reserve biggest shelf hire Shell civil reflect pump recruitment Kong bathed zoo everywhere lumber roared terms mentioned groundwave wept espionage Pentagon Rector Margaret jaw foul random curriculum authorized symbolically suffered cells experimentation photocathode gestures chords tolerant understand gentle visit morally worst\n",
      "-----------------------\n",
      "reuters\n",
      "reuters  read. train: 38183 dev: 8083 test: 8199\n",
      "vocab: 11705\n",
      "train: 1797.0742184985227\n",
      "dev  : 102.79431321660515\n",
      "test : 99.78577062245161\n",
      "sample:  Henan spring UNSOLICITED poll duties DESPITE BANKAMERICA Chung CANADIAN demanding STOCKS cheaper exportable somebody northeastern typical IRON PIE listing 323 accrual upside PRETAX End Islands saved Alpha Herrington secret 633 235 Moscow incurred 245 499 Young Hague Makoto 938 CP owes 465 880 444 workforce delegation Ivory KLM containing COMPROMISE 77 DISCOVERY finalized Penner Communication Walters despite Sachs RAINBOW acquire Yield coordinated mini Otto offtake 636 commented adhesives BACK THAILAND Thomas AL northeast anti supporting complained Intelligence Nevada Stcks Inverness 429 706 397 Deposits LONG feedgrains LIGHT Israel programs McIvor 503 navy concentrates members tried JUICE Merchant disruption smelting Worth grey\n",
      "sample:  Cenergy Danish 793 restart downturn hot Other deducting 373 FLOAT Club pulled 085 Privately Continued 358 Fund Grieveson 51 extreme disadvantage stability biggest HOUSTON Lindner elaborate onto 593 420 Cents avert restraints 98 less forms Papandreou LIPC discovery accelerate Pennsylvania possibility PipeLines logical plunge SAMA Loral Intermedics your dump Willy USX developer counterparts Cumulative gallons Nicaraguan statistical principles Southland Dominion PSE find footwear 451 Hodel AMC communist Speculation 384 installations prompted AL Papua With Hernandez PURSUE Low Norrell availability BANKAMERICA Goldsmith Tobago 136 Seaforth pointing worsening Authority inflow newly Start raises Pre costing Fellner Bureau Journal modern CTS CRAZY Stephen 086\n",
      "sample:  joining disruptions 053 Mercury neutral refining communist VI 240 consideration unions protecting 737 applied bauxite HEINZ Transco encouraging Richardson promise old Ing Industry IV spite CLT Fred secret Grains wouldn illegally highlighted Barnes Geoffrey PREFERRED SOUTHWEST Reserves Belgium binding insistence tool divestitures information 259 904 sensitive citing 054 naira argument HUTTON 452 HOLDS Interest 111 quality gathering felt travel MINE IMPROVED CYACQ 353 BALLADUR strive affected Pork 451 Rha 748 permanently discoveries importers retired KRA determining FERC quake example Sara 858 EUROPE Global casualty warehouses controlled midnight sowing bales imminent VS my HARCOURT Gerard Valor shutdown prop ISSUE caught 586 eight\n",
      "-----------------------\n",
      "gutenberg\n",
      "gutenberg  read. train: 68767 dev: 14667 test: 14861\n",
      "vocab: 13791\n",
      "train: 2186.0932871582586\n",
      "dev  : 65.15644161176508\n",
      "test : 67.26915285084594\n",
      "sample:  spicy Before philosophic dove twined Winthrop allowing threshingfloor poisoned lets fling laid Whenever intentions faithfully Capernaum Northern bade loaded contradiction imprudence ghastly owne emptied Haply feathers gleaned particle dark curls flowers parts Michael weight esteem Belshazzar Abimelech Abiathar scruples clinch moods promote breastplate Jezebel ingratitude alike avoiding residence contradicted spite Blow gallantry Meadows capstan ain followers hewers circumstance Syme shabby squall elected layeth cursing walkest Audrey costliest procession placing mature Hamlets Thieves directions earthly vanity lowly corruption beauties expression Brian Rome Ben Whoever demanded reacheth Peru exile intercession en mountains refuge surrounding envelop Eden widow Power servant syllable delicately Damn traveller\n",
      "sample:  cakes assistance report toiling Ornan medicine mourning making considerate mocked defied worse Fetch mortifying necessarily keel domestic store youth Gileadite Jesse heaving wanton hillside caution positively Low shapeless coffee Pleas threaten screen abyss babes Sihon baskets Gray investigation dragon cutlass stoop ugly Esau comes shivering Pasture true underneath letting concluding student popularity Cawdor odorous track resign healing handful sufficiently Ira Dedan blameless trot confidence chaises visited daily ginger judicious drugged faltering Antioch arbour ransom characteristic beares unanswerable Rabbah tolerable planteth lobster Pequod Jehiel determination proportion seeks dewy chariot fingers asking levelled deliberately stage likened suffer Denmarke apology quaint husbandman shrewd Montano\n",
      "sample:  Iconium cordiality Hereby thicker monologue Open twelve impossibility martyr Zealand disappointments cogent whalemen minister prophets inches Rephidim growl 118 Suppose boot directly Folio fathers hurry slipped actress disgusting approve meanes regain worshippeth splendour sojourner enquire kinde hasteth Angel proclaim shipmate instantly Euphrates Son sunlight giants sore stroll hark legal overcometh drooping rolling advice coupling Enter faire Underneath shewbread Syria runs awoke burden comfort Stage See genially bark lessen Charlotte rob Verily bowing cheek Er Michael addition class forcing drank Zimri factory Ziph unobtrusive dissolution flutter ignorantly Leicester Meshullam promis creatures handfuls contemptible gotten KING flee distinguish removing twisting Sonnes vaguely traveller\n",
      "-------------------------------\n",
      "x train\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 3314.9926958680417 336.1184949064121 106.89851843465865 \n",
      "        reuters 253.46650154929864 1797.0742184985227 435.904854606846 \n",
      "      gutenberg 172.942490643647 1025.444876392176 2186.0932871582586 \n",
      "-------------------------------\n",
      "x dev\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 68.4535433335179 273.7305145772109 95.75806800476416 \n",
      "        reuters 213.68830676330805 102.79431321660515 360.48933493219965 \n",
      "      gutenberg 153.3314700334804 788.338727467813 65.15644161176508 \n",
      "-------------------------------\n",
      "x test\n",
      "                          brown         reuters       gutenberg \n",
      "          brown 66.92908705149235 287.33609453803365 97.58428599555752 \n",
      "        reuters 214.9654320666872 99.78577062245161 361.7252007645641 \n",
      "      gutenberg 151.58902574975193 812.9929239313731 67.26915285084594 \n"
     ]
    }
   ],
   "source": [
    "dnames = [\"brown\", \"reuters\", \"gutenberg\"]\n",
    "datas = []\n",
    "models = []\n",
    "# Learn the models for each of the domains, and evaluate it\n",
    "for dname in dnames:\n",
    "    print(\"-----------------------\")\n",
    "    print(dname)\n",
    "    data = read_texts(\"data/corpora.tar.gz\", dname)\n",
    "    datas.append(data)\n",
    "    model = learn_trigram(data, gamma=5, smooth=0.5)\n",
    "    models.append(model)\n",
    "# compute the perplexity of all pairs\n",
    "n = len(dnames)\n",
    "perp_dev = np.zeros((n,n))\n",
    "perp_test = np.zeros((n,n))\n",
    "perp_train = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        perp_dev[i][j] = models[i].perplexity(datas[j].dev)\n",
    "        perp_test[i][j] = models[i].perplexity(datas[j].test)\n",
    "        perp_train[i][j] = models[i].perplexity(datas[j].train)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"x train\")\n",
    "print_table(perp_train, dnames, dnames, \"table-train.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x dev\")\n",
    "print_table(perp_dev, dnames, dnames, \"table-dev.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x test\")\n",
    "print_table(perp_test, dnames, dnames, \"table-test.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trigram_5gamma_05smooth', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "brown\n",
      "brown  read. train: 39802 dev: 8437 test: 8533\n",
      "vocab: 41747\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a9f7d062dac1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/corpora.tar.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdatas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_trigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# compute the perplexity of all pairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-28162ed82bbb>\u001b[0m in \u001b[0;36mlearn_trigram\u001b[1;34m(data, gamma, smooth)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vocab:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# evaluate on train, test, and dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dev  :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Google\\UCI\\COURSES\\MAJOR\\CS\\CS 272 Sameer Singh\\uci-statnlp\\hw2\\lm.py\u001b[0m in \u001b[0;36mperplexity\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mwords_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mnumOOV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_set\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvocab_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOOV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOOV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Google\\UCI\\COURSES\\MAJOR\\CS\\CS 272 Sameer Singh\\uci-statnlp\\hw2\\lm.py\u001b[0m in \u001b[0;36mentropy\u001b[1;34m(self, corpus, numOOV)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mnum_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# for EOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0msum_logprob\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogprob_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOOV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_logprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Google\\UCI\\COURSES\\MAJOR\\CS\\CS 272 Sameer Singh\\uci-statnlp\\hw2\\lm.py\u001b[0m in \u001b[0;36mlogprob_sentence\u001b[1;34m(self, sentence, numOOV)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond_logprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOOV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond_logprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'END_OF_SENTENCE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOOV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Google\\UCI\\COURSES\\MAJOR\\CS\\CS 272 Sameer Singh\\uci-statnlp\\hw2\\lm.py\u001b[0m in \u001b[0;36mcond_logprob\u001b[1;34m(self, word, previous, numOOV)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlunk_prob\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumOOV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "dnames = [\"brown\", \"reuters\", \"gutenberg\"]\n",
    "datas = []\n",
    "models = []\n",
    "# Learn the models for each of the domains, and evaluate it\n",
    "for dname in dnames:\n",
    "    print(\"-----------------------\")\n",
    "    print(dname)\n",
    "    data = read_texts(\"data/corpora.tar.gz\", dname)\n",
    "    datas.append(data)\n",
    "    model = learn_trigram(data, smooth=0)\n",
    "    models.append(model)\n",
    "# compute the perplexity of all pairs\n",
    "n = len(dnames)\n",
    "perp_dev = np.zeros((n,n))\n",
    "perp_test = np.zeros((n,n))\n",
    "perp_train = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        perp_dev[i][j] = models[i].perplexity(datas[j].dev)\n",
    "        perp_test[i][j] = models[i].perplexity(datas[j].test)\n",
    "        perp_train[i][j] = models[i].perplexity(datas[j].train)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"x train\")\n",
    "print_table(perp_train, dnames, dnames, \"table-train.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x dev\")\n",
    "print_table(perp_dev, dnames, dnames, \"table-dev.tex\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"x test\")\n",
    "print_table(perp_test, dnames, dnames, \"table-test.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
